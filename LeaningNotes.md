# Ch2  Deep Learning for NLP: Word Vectors and Lexical Semantics
- 词向量与词汇语义学

## 2.1 How to represent words
- Natural language text = sequences of discrete symbols
- Naive representation: one hot vectors in R|vocabulary|(very large)  
- Classical IR:document and query vectors are superpositions of word vectors.
- Similarly for word classification problems
- 